{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sepsis_comp_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Co8xcuBnNQ-"
      },
      "source": [
        "# install env\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6d-mjTgnpVe"
      },
      "source": [
        "# test env\n",
        "import torch\n",
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoYL-BfrnuI_"
      },
      "source": [
        "# mount google drive to env\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/My Drive/colab/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcaqeZ5Bnx2b"
      },
      "source": [
        "# tcn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size, padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "print(\"TCN component initialized\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN7hQVSFn0X_"
      },
      "source": [
        "# model\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
        "        super(TCN, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x needs to have dimension (N, C, L) in order to be passed into CNN\n",
        "        output = self.tcn(x.transpose(1, 2)).transpose(1, 2)\n",
        "        output = self.linear(output).float()\n",
        "        return self.sig(output)\n",
        "\n",
        "\n",
        "print(\"TCN model initialized\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeWmaLFGn-6w"
      },
      "source": [
        "# data_generator\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "nan_mode = 1 # method to manage NaN value\n",
        "data_dir = \"../data/training/\"\n",
        "\n",
        "\n",
        "def read_psv(f):\n",
        "  lines = f.readlines()\n",
        "  m = np.empty((len(lines)-1, 41), dtype=np.float32)\n",
        "  for i in range(1, len(lines)-1):\n",
        "    line = lines[i][:-1].split('|')\n",
        "    for j in range(len(line)):\n",
        "      m[i][j] = np.float32(line[j])\n",
        "  return m\n",
        "\n",
        "\n",
        "def data_generator():\n",
        "\n",
        "  file_name_pattern = 'p{:0=6}.psv'\n",
        "\n",
        "  file_index = list(range(0, 2000)) # set A max file index is 20643\n",
        "  # dataset_index = list(range(100000, 101000)) # set B max file index is 120000\n",
        "  np.random.seed(12334)\n",
        "  np.random.shuffle(file_index)\n",
        "  dataset_index = [\n",
        "    file_index[:round(len(file_index)*0.7)], # train_set_index\n",
        "    file_index[round(len(file_index)*0.7):round(len(file_index)*0.85)], # valid_set_index\n",
        "    file_index[round(len(file_index)*0.85):] # valid_set_index\n",
        "  ]\n",
        "\n",
        "  datas = [[], [], []]\n",
        "  \n",
        "  # read file\n",
        "  for i in range(len(dataset_index)):\n",
        "    for j in tqdm(range(len(dataset_index[i]))):\n",
        "      file_name = file_name_pattern.format(j + 1)\n",
        "      with open(data_dir + file_name) as datafile:\n",
        "        datas[i].append(read_psv(datafile))\n",
        "    \n",
        "  for data in datas:\n",
        "    for i in range(len(data)):\n",
        "        data[i] = torch.Tensor(data[i].astype(np.float32))\n",
        "\n",
        "  return datas[0], datas[1], datas[2]\n",
        "\n",
        "print(\"data generator initialized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkxPZvuXoEiO"
      },
      "source": [
        "# sepsis.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "_cuda = True\n",
        "_dropout = 0.25\n",
        "_clip = 0.2\n",
        "_epochs = 100\n",
        "_ksize = 5\n",
        "_levels = 4\n",
        "_log_interval = 100\n",
        "_lr = 1e-3\n",
        "_optim = 'Adam'\n",
        "_nhid = 150\n",
        "_seed = 6783\n",
        "input_size = 88\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(_seed)\n",
        "\n",
        "X_train, X_valid, X_test = data_generator()\n",
        "\n",
        "n_channels = [_nhid] * _levels\n",
        "kernel_size = _ksize\n",
        "dropout = _dropout\n",
        "\n",
        "model = TCN(input_size, 1, n_channels, kernel_size, dropout=_dropout)\n",
        "\n",
        "\n",
        "if _cuda:\n",
        "    model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = _lr\n",
        "optimizer = getattr(optim, _optim)(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def evaluate(X_data, name='Eval'):\n",
        "    model.eval()\n",
        "    eval_idx_list = np.arange(len(X_data), dtype=\"int32\")\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for idx in eval_idx_list:\n",
        "            data_line = X_data[idx]\n",
        "            x, y = Variable(data_line[:-1]), Variable(data_line[1:])\n",
        "            if _cuda:\n",
        "                x, y = x.cuda(), y.cuda()\n",
        "            output = model(x.unsqueeze(0)).squeeze(0)\n",
        "            loss = -torch.trace(torch.matmul(y, torch.log(output).float().t()) +\n",
        "                                torch.matmul((1-y), torch.log(1-output).float().t()))\n",
        "            total_loss += loss.item()\n",
        "            count += output.size(0)\n",
        "        eval_loss = total_loss / count\n",
        "        print(name + \" loss: {:.5f}\".format(eval_loss))\n",
        "        return eval_loss\n",
        "\n",
        "\n",
        "def train(ep):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    train_idx_list = np.arange(len(X_train), dtype=\"int32\")\n",
        "    np.random.shuffle(train_idx_list)\n",
        "    for idx in train_idx_list:\n",
        "        data_line = X_train[idx]\n",
        "        x, y = Variable(data_line[:-1]), Variable(data_line[1:])\n",
        "        if _cuda:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x.unsqueeze(0)).squeeze(0)\n",
        "        loss = -torch.trace(torch.matmul(y, torch.log(output).float().t()) +\n",
        "                            torch.matmul((1 - y), torch.log(1 - output).float().t()))\n",
        "        total_loss += loss.item()\n",
        "        count += output.size(0)\n",
        "\n",
        "        if _clip > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), _clip)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if idx > 0 and idx % _log_interval == 0:\n",
        "            cur_loss = total_loss / count\n",
        "            print(\"Epoch {:2d} | lr {:.5f} | loss {:.5f}\".format(ep, lr, cur_loss))\n",
        "            total_loss = 0.0\n",
        "            count = 0\n",
        "\n",
        "best_vloss = 1e8\n",
        "vloss_list = []\n",
        "model_name = \"poly_music_{0}.pt\".format(_data)\n",
        "for ep in range(1, _epochs+1):\n",
        "    train(ep)\n",
        "    vloss = evaluate(X_valid, name='Validation')\n",
        "    tloss = evaluate(X_test, name='Test')\n",
        "    if vloss < best_vloss:\n",
        "        with open(model_name, \"wb\") as f:\n",
        "            torch.save(model, f)\n",
        "            print(\"Saved model!\\n\")\n",
        "        best_vloss = vloss\n",
        "    if ep > 10 and vloss > max(vloss_list[-3:]):\n",
        "        lr /= 10\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    vloss_list.append(vloss)\n",
        "\n",
        "print('-' * 89)\n",
        "model = torch.load(open(model_name, \"rb\"))\n",
        "tloss = evaluate(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}